{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "025e1b42",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting transformers\n",
      "  Downloading transformers-4.53.1-py3-none-any.whl.metadata (40 kB)\n",
      "Requirement already satisfied: filelock in c:\\users\\admin\\desktop\\김송미\\10_핀테크대체데이터분석\\source\\.venv\\lib\\site-packages (from transformers) (3.18.0)\n",
      "Collecting huggingface-hub<1.0,>=0.30.0 (from transformers)\n",
      "  Downloading huggingface_hub-0.33.2-py3-none-any.whl.metadata (14 kB)\n",
      "Requirement already satisfied: numpy>=1.17 in c:\\users\\admin\\desktop\\김송미\\10_핀테크대체데이터분석\\source\\.venv\\lib\\site-packages (from transformers) (2.1.3)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\admin\\desktop\\김송미\\10_핀테크대체데이터분석\\source\\.venv\\lib\\site-packages (from transformers) (25.0)\n",
      "Collecting pyyaml>=5.1 (from transformers)\n",
      "  Downloading PyYAML-6.0.2-cp312-cp312-win_amd64.whl.metadata (2.1 kB)\n",
      "Collecting regex!=2019.12.17 (from transformers)\n",
      "  Downloading regex-2024.11.6-cp312-cp312-win_amd64.whl.metadata (41 kB)\n",
      "Requirement already satisfied: requests in c:\\users\\admin\\desktop\\김송미\\10_핀테크대체데이터분석\\source\\.venv\\lib\\site-packages (from transformers) (2.32.4)\n",
      "Collecting tokenizers<0.22,>=0.21 (from transformers)\n",
      "  Downloading tokenizers-0.21.2-cp39-abi3-win_amd64.whl.metadata (6.9 kB)\n",
      "Collecting safetensors>=0.4.3 (from transformers)\n",
      "  Downloading safetensors-0.5.3-cp38-abi3-win_amd64.whl.metadata (3.9 kB)\n",
      "Collecting tqdm>=4.27 (from transformers)\n",
      "  Downloading tqdm-4.67.1-py3-none-any.whl.metadata (57 kB)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in c:\\users\\admin\\desktop\\김송미\\10_핀테크대체데이터분석\\source\\.venv\\lib\\site-packages (from huggingface-hub<1.0,>=0.30.0->transformers) (2025.5.1)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in c:\\users\\admin\\desktop\\김송미\\10_핀테크대체데이터분석\\source\\.venv\\lib\\site-packages (from huggingface-hub<1.0,>=0.30.0->transformers) (4.14.1)\n",
      "Requirement already satisfied: colorama in c:\\users\\admin\\desktop\\김송미\\10_핀테크대체데이터분석\\source\\.venv\\lib\\site-packages (from tqdm>=4.27->transformers) (0.4.6)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in c:\\users\\admin\\desktop\\김송미\\10_핀테크대체데이터분석\\source\\.venv\\lib\\site-packages (from requests->transformers) (3.4.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\admin\\desktop\\김송미\\10_핀테크대체데이터분석\\source\\.venv\\lib\\site-packages (from requests->transformers) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\admin\\desktop\\김송미\\10_핀테크대체데이터분석\\source\\.venv\\lib\\site-packages (from requests->transformers) (2.5.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\admin\\desktop\\김송미\\10_핀테크대체데이터분석\\source\\.venv\\lib\\site-packages (from requests->transformers) (2025.6.15)\n",
      "Downloading transformers-4.53.1-py3-none-any.whl (10.8 MB)\n",
      "   ---------------------------------------- 0.0/10.8 MB ? eta -:--:--\n",
      "   ------------------------------------ --- 10.0/10.8 MB 47.8 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 10.8/10.8 MB 42.3 MB/s eta 0:00:00\n",
      "Downloading huggingface_hub-0.33.2-py3-none-any.whl (515 kB)\n",
      "Downloading tokenizers-0.21.2-cp39-abi3-win_amd64.whl (2.5 MB)\n",
      "   ---------------------------------------- 0.0/2.5 MB ? eta -:--:--\n",
      "   ---------------------------------------- 2.5/2.5 MB 36.3 MB/s eta 0:00:00\n",
      "Downloading PyYAML-6.0.2-cp312-cp312-win_amd64.whl (156 kB)\n",
      "Downloading regex-2024.11.6-cp312-cp312-win_amd64.whl (273 kB)\n",
      "Downloading safetensors-0.5.3-cp38-abi3-win_amd64.whl (308 kB)\n",
      "Downloading tqdm-4.67.1-py3-none-any.whl (78 kB)\n",
      "Installing collected packages: tqdm, safetensors, regex, pyyaml, huggingface-hub, tokenizers, transformers\n",
      "\n",
      "   ---------------------------------------- 0/7 [tqdm]\n",
      "   ---------------------------------------- 0/7 [tqdm]\n",
      "   ----------- ---------------------------- 2/7 [regex]\n",
      "   ----------------- ---------------------- 3/7 [pyyaml]\n",
      "   ---------------------- ----------------- 4/7 [huggingface-hub]\n",
      "   ---------------------- ----------------- 4/7 [huggingface-hub]\n",
      "   ---------------------- ----------------- 4/7 [huggingface-hub]\n",
      "   ---------------------- ----------------- 4/7 [huggingface-hub]\n",
      "   ---------------------- ----------------- 4/7 [huggingface-hub]\n",
      "   ---------------------- ----------------- 4/7 [huggingface-hub]\n",
      "   ---------------------- ----------------- 4/7 [huggingface-hub]\n",
      "   ---------------------- ----------------- 4/7 [huggingface-hub]\n",
      "   ---------------------- ----------------- 4/7 [huggingface-hub]\n",
      "   ---------------------- ----------------- 4/7 [huggingface-hub]\n",
      "   ---------------------------- ----------- 5/7 [tokenizers]\n",
      "   ---------------------------------- ----- 6/7 [transformers]\n",
      "   ---------------------------------- ----- 6/7 [transformers]\n",
      "   ---------------------------------- ----- 6/7 [transformers]\n",
      "   ---------------------------------- ----- 6/7 [transformers]\n",
      "   ---------------------------------- ----- 6/7 [transformers]\n",
      "   ---------------------------------- ----- 6/7 [transformers]\n",
      "   ---------------------------------- ----- 6/7 [transformers]\n",
      "   ---------------------------------- ----- 6/7 [transformers]\n",
      "   ---------------------------------- ----- 6/7 [transformers]\n",
      "   ---------------------------------- ----- 6/7 [transformers]\n",
      "   ---------------------------------- ----- 6/7 [transformers]\n",
      "   ---------------------------------- ----- 6/7 [transformers]\n",
      "   ---------------------------------- ----- 6/7 [transformers]\n",
      "   ---------------------------------- ----- 6/7 [transformers]\n",
      "   ---------------------------------- ----- 6/7 [transformers]\n",
      "   ---------------------------------- ----- 6/7 [transformers]\n",
      "   ---------------------------------- ----- 6/7 [transformers]\n",
      "   ---------------------------------- ----- 6/7 [transformers]\n",
      "   ---------------------------------- ----- 6/7 [transformers]\n",
      "   ---------------------------------- ----- 6/7 [transformers]\n",
      "   ---------------------------------- ----- 6/7 [transformers]\n",
      "   ---------------------------------- ----- 6/7 [transformers]\n",
      "   ---------------------------------- ----- 6/7 [transformers]\n",
      "   ---------------------------------- ----- 6/7 [transformers]\n",
      "   ---------------------------------- ----- 6/7 [transformers]\n",
      "   ---------------------------------- ----- 6/7 [transformers]\n",
      "   ---------------------------------- ----- 6/7 [transformers]\n",
      "   ---------------------------------- ----- 6/7 [transformers]\n",
      "   ---------------------------------- ----- 6/7 [transformers]\n",
      "   ---------------------------------- ----- 6/7 [transformers]\n",
      "   ---------------------------------- ----- 6/7 [transformers]\n",
      "   ---------------------------------- ----- 6/7 [transformers]\n",
      "   ---------------------------------- ----- 6/7 [transformers]\n",
      "   ---------------------------------- ----- 6/7 [transformers]\n",
      "   ---------------------------------- ----- 6/7 [transformers]\n",
      "   ---------------------------------- ----- 6/7 [transformers]\n",
      "   ---------------------------------- ----- 6/7 [transformers]\n",
      "   ---------------------------------- ----- 6/7 [transformers]\n",
      "   ---------------------------------- ----- 6/7 [transformers]\n",
      "   ---------------------------------- ----- 6/7 [transformers]\n",
      "   ---------------------------------- ----- 6/7 [transformers]\n",
      "   ---------------------------------- ----- 6/7 [transformers]\n",
      "   ---------------------------------- ----- 6/7 [transformers]\n",
      "   ---------------------------------- ----- 6/7 [transformers]\n",
      "   ---------------------------------- ----- 6/7 [transformers]\n",
      "   ---------------------------------- ----- 6/7 [transformers]\n",
      "   ---------------------------------- ----- 6/7 [transformers]\n",
      "   ---------------------------------- ----- 6/7 [transformers]\n",
      "   ---------------------------------- ----- 6/7 [transformers]\n",
      "   ---------------------------------- ----- 6/7 [transformers]\n",
      "   ---------------------------------- ----- 6/7 [transformers]\n",
      "   ---------------------------------- ----- 6/7 [transformers]\n",
      "   ---------------------------------- ----- 6/7 [transformers]\n",
      "   ---------------------------------- ----- 6/7 [transformers]\n",
      "   ---------------------------------- ----- 6/7 [transformers]\n",
      "   ---------------------------------- ----- 6/7 [transformers]\n",
      "   ---------------------------------- ----- 6/7 [transformers]\n",
      "   ---------------------------------- ----- 6/7 [transformers]\n",
      "   ---------------------------------- ----- 6/7 [transformers]\n",
      "   ---------------------------------- ----- 6/7 [transformers]\n",
      "   ---------------------------------- ----- 6/7 [transformers]\n",
      "   ---------------------------------- ----- 6/7 [transformers]\n",
      "   ---------------------------------- ----- 6/7 [transformers]\n",
      "   ---------------------------------- ----- 6/7 [transformers]\n",
      "   ---------------------------------- ----- 6/7 [transformers]\n",
      "   ---------------------------------- ----- 6/7 [transformers]\n",
      "   ---------------------------------- ----- 6/7 [transformers]\n",
      "   ---------------------------------- ----- 6/7 [transformers]\n",
      "   ---------------------------------- ----- 6/7 [transformers]\n",
      "   ---------------------------------- ----- 6/7 [transformers]\n",
      "   ---------------------------------- ----- 6/7 [transformers]\n",
      "   ---------------------------------- ----- 6/7 [transformers]\n",
      "   ---------------------------------- ----- 6/7 [transformers]\n",
      "   ---------------------------------- ----- 6/7 [transformers]\n",
      "   ---------------------------------- ----- 6/7 [transformers]\n",
      "   ---------------------------------- ----- 6/7 [transformers]\n",
      "   ---------------------------------- ----- 6/7 [transformers]\n",
      "   ---------------------------------- ----- 6/7 [transformers]\n",
      "   ---------------------------------- ----- 6/7 [transformers]\n",
      "   ---------------------------------- ----- 6/7 [transformers]\n",
      "   ---------------------------------- ----- 6/7 [transformers]\n",
      "   ---------------------------------- ----- 6/7 [transformers]\n",
      "   ---------------------------------- ----- 6/7 [transformers]\n",
      "   ---------------------------------- ----- 6/7 [transformers]\n",
      "   ---------------------------------- ----- 6/7 [transformers]\n",
      "   ---------------------------------- ----- 6/7 [transformers]\n",
      "   ---------------------------------- ----- 6/7 [transformers]\n",
      "   ---------------------------------- ----- 6/7 [transformers]\n",
      "   ---------------------------------- ----- 6/7 [transformers]\n",
      "   ---------------------------------- ----- 6/7 [transformers]\n",
      "   ---------------------------------- ----- 6/7 [transformers]\n",
      "   ---------------------------------- ----- 6/7 [transformers]\n",
      "   ---------------------------------- ----- 6/7 [transformers]\n",
      "   ---------------------------------- ----- 6/7 [transformers]\n",
      "   ---------------------------------- ----- 6/7 [transformers]\n",
      "   ---------------------------------- ----- 6/7 [transformers]\n",
      "   ---------------------------------- ----- 6/7 [transformers]\n",
      "   ---------------------------------- ----- 6/7 [transformers]\n",
      "   ---------------------------------- ----- 6/7 [transformers]\n",
      "   ---------------------------------- ----- 6/7 [transformers]\n",
      "   ---------------------------------- ----- 6/7 [transformers]\n",
      "   ---------------------------------- ----- 6/7 [transformers]\n",
      "   ---------------------------------- ----- 6/7 [transformers]\n",
      "   ---------------------------------- ----- 6/7 [transformers]\n",
      "   ---------------------------------- ----- 6/7 [transformers]\n",
      "   ---------------------------------- ----- 6/7 [transformers]\n",
      "   ---------------------------------- ----- 6/7 [transformers]\n",
      "   ---------------------------------- ----- 6/7 [transformers]\n",
      "   ---------------------------------- ----- 6/7 [transformers]\n",
      "   ---------------------------------- ----- 6/7 [transformers]\n",
      "   ---------------------------------- ----- 6/7 [transformers]\n",
      "   ---------------------------------- ----- 6/7 [transformers]\n",
      "   ---------------------------------- ----- 6/7 [transformers]\n",
      "   ---------------------------------- ----- 6/7 [transformers]\n",
      "   ---------------------------------- ----- 6/7 [transformers]\n",
      "   ---------------------------------- ----- 6/7 [transformers]\n",
      "   ---------------------------------- ----- 6/7 [transformers]\n",
      "   ---------------------------------- ----- 6/7 [transformers]\n",
      "   ---------------------------------- ----- 6/7 [transformers]\n",
      "   ---------------------------------- ----- 6/7 [transformers]\n",
      "   ---------------------------------- ----- 6/7 [transformers]\n",
      "   ---------------------------------- ----- 6/7 [transformers]\n",
      "   ---------------------------------- ----- 6/7 [transformers]\n",
      "   ---------------------------------- ----- 6/7 [transformers]\n",
      "   ---------------------------------- ----- 6/7 [transformers]\n",
      "   ---------------------------------- ----- 6/7 [transformers]\n",
      "   ---------------------------------- ----- 6/7 [transformers]\n",
      "   ---------------------------------- ----- 6/7 [transformers]\n",
      "   ---------------------------------- ----- 6/7 [transformers]\n",
      "   ---------------------------------- ----- 6/7 [transformers]\n",
      "   ---------------------------------- ----- 6/7 [transformers]\n",
      "   ---------------------------------- ----- 6/7 [transformers]\n",
      "   ---------------------------------- ----- 6/7 [transformers]\n",
      "   ---------------------------------- ----- 6/7 [transformers]\n",
      "   ---------------------------------- ----- 6/7 [transformers]\n",
      "   ---------------------------------------- 7/7 [transformers]\n",
      "\n",
      "Successfully installed huggingface-hub-0.33.2 pyyaml-6.0.2 regex-2024.11.6 safetensors-0.5.3 tokenizers-0.21.2 tqdm-4.67.1 transformers-4.53.1\n"
     ]
    }
   ],
   "source": [
    "!pip install transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "653de1b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting tf_keras\n",
      "  Using cached tf_keras-2.19.0-py3-none-any.whl.metadata (1.8 kB)\n",
      "Requirement already satisfied: tensorflow<2.20,>=2.19 in c:\\users\\admin\\desktop\\김송미\\10_핀테크대체데이터분석\\source\\.venv\\lib\\site-packages (from tf_keras) (2.19.0)\n",
      "Requirement already satisfied: absl-py>=1.0.0 in c:\\users\\admin\\desktop\\김송미\\10_핀테크대체데이터분석\\source\\.venv\\lib\\site-packages (from tensorflow<2.20,>=2.19->tf_keras) (2.3.1)\n",
      "Requirement already satisfied: astunparse>=1.6.0 in c:\\users\\admin\\desktop\\김송미\\10_핀테크대체데이터분석\\source\\.venv\\lib\\site-packages (from tensorflow<2.20,>=2.19->tf_keras) (1.6.3)\n",
      "Requirement already satisfied: flatbuffers>=24.3.25 in c:\\users\\admin\\desktop\\김송미\\10_핀테크대체데이터분석\\source\\.venv\\lib\\site-packages (from tensorflow<2.20,>=2.19->tf_keras) (25.2.10)\n",
      "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in c:\\users\\admin\\desktop\\김송미\\10_핀테크대체데이터분석\\source\\.venv\\lib\\site-packages (from tensorflow<2.20,>=2.19->tf_keras) (0.6.0)\n",
      "Requirement already satisfied: google-pasta>=0.1.1 in c:\\users\\admin\\desktop\\김송미\\10_핀테크대체데이터분석\\source\\.venv\\lib\\site-packages (from tensorflow<2.20,>=2.19->tf_keras) (0.2.0)\n",
      "Requirement already satisfied: libclang>=13.0.0 in c:\\users\\admin\\desktop\\김송미\\10_핀테크대체데이터분석\\source\\.venv\\lib\\site-packages (from tensorflow<2.20,>=2.19->tf_keras) (18.1.1)\n",
      "Requirement already satisfied: opt-einsum>=2.3.2 in c:\\users\\admin\\desktop\\김송미\\10_핀테크대체데이터분석\\source\\.venv\\lib\\site-packages (from tensorflow<2.20,>=2.19->tf_keras) (3.4.0)\n",
      "Requirement already satisfied: packaging in c:\\users\\admin\\desktop\\김송미\\10_핀테크대체데이터분석\\source\\.venv\\lib\\site-packages (from tensorflow<2.20,>=2.19->tf_keras) (25.0)\n",
      "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0dev,>=3.20.3 in c:\\users\\admin\\desktop\\김송미\\10_핀테크대체데이터분석\\source\\.venv\\lib\\site-packages (from tensorflow<2.20,>=2.19->tf_keras) (5.29.5)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in c:\\users\\admin\\desktop\\김송미\\10_핀테크대체데이터분석\\source\\.venv\\lib\\site-packages (from tensorflow<2.20,>=2.19->tf_keras) (2.32.4)\n",
      "Requirement already satisfied: setuptools in c:\\users\\admin\\desktop\\김송미\\10_핀테크대체데이터분석\\source\\.venv\\lib\\site-packages (from tensorflow<2.20,>=2.19->tf_keras) (80.9.0)\n",
      "Requirement already satisfied: six>=1.12.0 in c:\\users\\admin\\desktop\\김송미\\10_핀테크대체데이터분석\\source\\.venv\\lib\\site-packages (from tensorflow<2.20,>=2.19->tf_keras) (1.17.0)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in c:\\users\\admin\\desktop\\김송미\\10_핀테크대체데이터분석\\source\\.venv\\lib\\site-packages (from tensorflow<2.20,>=2.19->tf_keras) (3.1.0)\n",
      "Requirement already satisfied: typing-extensions>=3.6.6 in c:\\users\\admin\\desktop\\김송미\\10_핀테크대체데이터분석\\source\\.venv\\lib\\site-packages (from tensorflow<2.20,>=2.19->tf_keras) (4.14.1)\n",
      "Requirement already satisfied: wrapt>=1.11.0 in c:\\users\\admin\\desktop\\김송미\\10_핀테크대체데이터분석\\source\\.venv\\lib\\site-packages (from tensorflow<2.20,>=2.19->tf_keras) (1.17.2)\n",
      "Requirement already satisfied: grpcio<2.0,>=1.24.3 in c:\\users\\admin\\desktop\\김송미\\10_핀테크대체데이터분석\\source\\.venv\\lib\\site-packages (from tensorflow<2.20,>=2.19->tf_keras) (1.73.1)\n",
      "Requirement already satisfied: tensorboard~=2.19.0 in c:\\users\\admin\\desktop\\김송미\\10_핀테크대체데이터분석\\source\\.venv\\lib\\site-packages (from tensorflow<2.20,>=2.19->tf_keras) (2.19.0)\n",
      "Requirement already satisfied: keras>=3.5.0 in c:\\users\\admin\\desktop\\김송미\\10_핀테크대체데이터분석\\source\\.venv\\lib\\site-packages (from tensorflow<2.20,>=2.19->tf_keras) (3.10.0)\n",
      "Requirement already satisfied: numpy<2.2.0,>=1.26.0 in c:\\users\\admin\\desktop\\김송미\\10_핀테크대체데이터분석\\source\\.venv\\lib\\site-packages (from tensorflow<2.20,>=2.19->tf_keras) (2.1.3)\n",
      "Requirement already satisfied: h5py>=3.11.0 in c:\\users\\admin\\desktop\\김송미\\10_핀테크대체데이터분석\\source\\.venv\\lib\\site-packages (from tensorflow<2.20,>=2.19->tf_keras) (3.14.0)\n",
      "Requirement already satisfied: ml-dtypes<1.0.0,>=0.5.1 in c:\\users\\admin\\desktop\\김송미\\10_핀테크대체데이터분석\\source\\.venv\\lib\\site-packages (from tensorflow<2.20,>=2.19->tf_keras) (0.5.1)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in c:\\users\\admin\\desktop\\김송미\\10_핀테크대체데이터분석\\source\\.venv\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow<2.20,>=2.19->tf_keras) (3.4.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\admin\\desktop\\김송미\\10_핀테크대체데이터분석\\source\\.venv\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow<2.20,>=2.19->tf_keras) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\admin\\desktop\\김송미\\10_핀테크대체데이터분석\\source\\.venv\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow<2.20,>=2.19->tf_keras) (2.5.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\admin\\desktop\\김송미\\10_핀테크대체데이터분석\\source\\.venv\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow<2.20,>=2.19->tf_keras) (2025.6.15)\n",
      "Requirement already satisfied: markdown>=2.6.8 in c:\\users\\admin\\desktop\\김송미\\10_핀테크대체데이터분석\\source\\.venv\\lib\\site-packages (from tensorboard~=2.19.0->tensorflow<2.20,>=2.19->tf_keras) (3.8.2)\n",
      "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in c:\\users\\admin\\desktop\\김송미\\10_핀테크대체데이터분석\\source\\.venv\\lib\\site-packages (from tensorboard~=2.19.0->tensorflow<2.20,>=2.19->tf_keras) (0.7.2)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in c:\\users\\admin\\desktop\\김송미\\10_핀테크대체데이터분석\\source\\.venv\\lib\\site-packages (from tensorboard~=2.19.0->tensorflow<2.20,>=2.19->tf_keras) (3.1.3)\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in c:\\users\\admin\\desktop\\김송미\\10_핀테크대체데이터분석\\source\\.venv\\lib\\site-packages (from astunparse>=1.6.0->tensorflow<2.20,>=2.19->tf_keras) (0.45.1)\n",
      "Requirement already satisfied: rich in c:\\users\\admin\\desktop\\김송미\\10_핀테크대체데이터분석\\source\\.venv\\lib\\site-packages (from keras>=3.5.0->tensorflow<2.20,>=2.19->tf_keras) (14.0.0)\n",
      "Requirement already satisfied: namex in c:\\users\\admin\\desktop\\김송미\\10_핀테크대체데이터분석\\source\\.venv\\lib\\site-packages (from keras>=3.5.0->tensorflow<2.20,>=2.19->tf_keras) (0.1.0)\n",
      "Requirement already satisfied: optree in c:\\users\\admin\\desktop\\김송미\\10_핀테크대체데이터분석\\source\\.venv\\lib\\site-packages (from keras>=3.5.0->tensorflow<2.20,>=2.19->tf_keras) (0.16.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.1.1 in c:\\users\\admin\\desktop\\김송미\\10_핀테크대체데이터분석\\source\\.venv\\lib\\site-packages (from werkzeug>=1.0.1->tensorboard~=2.19.0->tensorflow<2.20,>=2.19->tf_keras) (3.0.2)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in c:\\users\\admin\\desktop\\김송미\\10_핀테크대체데이터분석\\source\\.venv\\lib\\site-packages (from rich->keras>=3.5.0->tensorflow<2.20,>=2.19->tf_keras) (3.0.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in c:\\users\\admin\\desktop\\김송미\\10_핀테크대체데이터분석\\source\\.venv\\lib\\site-packages (from rich->keras>=3.5.0->tensorflow<2.20,>=2.19->tf_keras) (2.19.2)\n",
      "Requirement already satisfied: mdurl~=0.1 in c:\\users\\admin\\desktop\\김송미\\10_핀테크대체데이터분석\\source\\.venv\\lib\\site-packages (from markdown-it-py>=2.2.0->rich->keras>=3.5.0->tensorflow<2.20,>=2.19->tf_keras) (0.1.2)\n",
      "Using cached tf_keras-2.19.0-py3-none-any.whl (1.7 MB)\n",
      "Installing collected packages: tf_keras\n",
      "Successfully installed tf_keras-2.19.0\n"
     ]
    }
   ],
   "source": [
    "!pip install tf_keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0d862b4e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\admin\\Desktop\\김송미\\10_핀테크대체데이터분석\\source\\.venv\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from transformers import pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57f20f45",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No model was supplied, defaulted to sshleifer/distilbart-cnn-12-6 and revision a4f8f3e (https://huggingface.co/sshleifer/distilbart-cnn-12-6).\n",
      "Using a pipeline without specifying a model name and revision in production is not recommended.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\Users\\admin\\Desktop\\김송미\\10_핀테크대체데이터분석\\source\\.venv\\Lib\\site-packages\\tf_keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cpu\n"
     ]
    }
   ],
   "source": [
    "pipe = pipeline(task=\"summarization\", model='sshleifer/distilbart-cnn-12-6')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9d3bdbf6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'summary_text': \" Vincent Willem van Gogh was a Dutch Post-Impressionist painter . His oeuvre includes landscapes, still lifes, portraits and self-portraits . Van Gogh's work was beginning to gain critical attention before he died from a self-inflicted gunshot at age 37 .\"}]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_text = \"\"\"Vincent Willem van Gogh was a Dutch Post-Impressionist painter who is among the most famous and influential figures in the history of Western art. In just over a decade, he created approximately 2100 artworks, including around 860 oil paintings, most of them in the last two years of his life. His oeuvre includes landscapes, still lifes, portraits, and self-portraits, most of which are characterised by bold colours and dramatic brushwork that contributed to the rise of expressionism in modern art. Van Gogh's work was beginning to gain critical attention before he died from a self-inflicted gunshot at age 37. During his lifetime, only one of Van Gogh's paintings, The Red Vineyard, was sold.\n",
    "\"\"\"\n",
    "pipe(sample_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "37e50676",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\admin\\Desktop\\김송미\\10_핀테크대체데이터분석\\source\\.venv\\Lib\\site-packages\\huggingface_hub\\file_download.py:143: UserWarning: `huggingface_hub` cache-system uses symlinks by default to efficiently store duplicated files but your machine does not support them in C:\\Users\\admin\\.cache\\huggingface\\hub\\models--EbanLee--kobart-summary-v3. Caching files will still work but in a degraded version that might require more space on your disk. This warning can be disabled by setting the `HF_HUB_DISABLE_SYMLINKS_WARNING` environment variable. For more details, see https://huggingface.co/docs/huggingface_hub/how-to-cache#limitations.\n",
      "To support symlinks on Windows, you either need to activate Developer Mode or to run Python as an administrator. In order to activate developer mode, see this article: https://docs.microsoft.com/en-us/windows/apps/get-started/enable-your-device-for-development\n",
      "  warnings.warn(message)\n",
      "You passed along `num_labels=3` with an incompatible id to label map: {'0': 'NEGATIVE', '1': 'POSITIVE'}. The number of labels will be overwritten to 2.\n",
      "You passed along `num_labels=3` with an incompatible id to label map: {'0': 'NEGATIVE', '1': 'POSITIVE'}. The number of labels will be overwritten to 2.\n",
      "Device set to use cpu\n"
     ]
    }
   ],
   "source": [
    "kobart = pipeline(task=\"summarization\", model=\"EbanLee/kobart-summary-v3\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ba970304",
   "metadata": {},
   "outputs": [],
   "source": [
    "ko_text = \"\"\"하나, ‘입문자 맞춤형 7단계 구성’을 따라가며 체계적으로 반복하는 탄탄한 학습 설계!\n",
    "이 책은 데이터 분석의 핵심 내용을 7단계에 걸쳐 반복 학습하면서 자연스럽게 머릿속에 기억되도록 구성했습니다. [핵심 키워드]와 [시작하기 전에]에서 각 절의 주제에 대한 대표 개념을 워밍업하고, 이론과 실습을 거쳐 마무리에서는 [핵심 포인트]와 [확인 문제]로 한번에 복습합니다. ‘혼자 공부할 수 있는’ 커리큘럼을 그대로 믿고 끝까지 따라가다 보면 데이터 분석 공부가 난생 처음인 입문자도 무리 없이 책을 끝까지 마칠 수 있습니다!\n",
    "둘, 실제로 일어날 법한 흥미로운 스토리에 담긴 문제를 직접 해결하며 익히는 ‘진짜’ 데이터 분석!\n",
    "현장감 넘치는 스토리를 통해 데이터를 다루는 방법을 알려 주어 ‘파이썬’과 ‘데이터’가 낯설어도 몰입감 있는 학습을 할 수 있도록 구성했습니다. 이 책에서는 API와 웹 스크래핑을 통해 실제 도서관 데이터와 온라인 서점 웹사이트에서 데이터를 가져오는 등 내 주변에 있는 데이터를 직접 수집할 수 있는 방법을 가이드합니다. 또한 판다스, 넘파이, 맷플롯립 등 데이터 분석에 유용한 각종 파이썬 라이브러리를 활용해 보며 코딩 감각을 익히고, 핵심 통계 지식으로 기본기를 탄탄하게 다질 수 있습니다. 마지막에는 분석을 바탕으로 미래를 예측하는 머신러닝까지 맛볼 수 있어 데이터 분석의 처음부터 끝까지 제대로 배울 수 있습니다.\n",
    "셋, ‘혼공’의 힘을 실어줄 동영상 강의와 혼공 학습 사이트 지원!\n",
    "책으로만 학습하기엔 여전히 어려운 입문자를 위해 저자 직강 동영상도 지원합니다. 또한 학습을 하며 궁금한 사항은 언제든지 저자에게 질문할 수 있도록 학습 사이트를 제공합니다. 저자가 질문 하나하나에 직접 답변을 달아 주는 것은 물론, 관련 최신 기술과 정보도 얻을 수 있습니다. 게다가 혼자 공부하고 싶지만 정작 혼자서는 자신 없는 사람들을 위해 혼공 학습단을 운영합니다. 혼공 학습단과 함께하면 마지막까지 포기하지 않고 완주할 수 있을 것입니다.\n",
    "▶ https://hongong.hanbit.co.kr\n",
    "▶ https://github.com/rickiepark/hg-da\n",
    "넷, 언제 어디서든 가볍게 볼 수 있는 혼공 필수 [용어 노트] 제공!\n",
    "꼭 기억해야 할 핵심 개념과 용어만 따로 정리한 [용어 노트]를 제공합니다. 처음 공부하는 사람들이 프로그래밍을 어려워하는 이유는 낯선 용어 때문입니다. 그러나 어려운 것이 아니라 익숙하지 않아서 헷갈리는 것이므로, 용어나 개념이 잘 생각나지 않을 때는 언제든 부담 없이 [용어 노트]를 펼쳐 보세요. 제시된 용어 외에도 새로운 용어를 추가하면서 자신만의 용어 노트를 완성해가는 과정도 또 다른 재미가 될 것입니다.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84578801",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'summary_text': '이 책은 데이터 분석의 핵심 내용을 7단계에 걸쳐 반복 학습하면서 머릿속에 기억되도록 구성했습니다. 독자 공부할 수 있는 커리큘럼을 그대로 믿고 끝까지 따라가다 보면 데이터 분석 공부가 난생 처음인 입문자도 무리 없이 책을 끝까지 마칠 수 있습니다. 현장감 넘치는 스토리를 통해 데이터를 다루는 방법을 알려 주어 몰입감 있는 학습을 할 수 있도록 구성했습니다. 저자가 질문 하나하나에 직접 답변을 달아 주는 것은 물론, 최신 기술과 정보도 얻을 수 있습니다. 혼공 학습단과 함께하면 마지막까지 포기하지 않고 완주할 수 있을 것입니다. 꼭 기억해야 할 핵심 개념과 용어만 따로 정리한 [용어 노트]를 제공합니다. 새로운 용어를 추가하면서 자신만의 용어 노트를 완성해가는 과정도 재미가 될 것입니다.'}]\n"
     ]
    }
   ],
   "source": [
    "kobart(ko_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "207600fa",
   "metadata": {},
   "source": [
    "이 책은 데이터 분석의 핵심 내용을 7단계에 걸쳐 반복 학습하면서 머릿속에 기억되도록 구성했습니다. 독자 공부할 수 있는 커리큘럼을 그대로 믿고 끝까지 따라가다 보면 데이터 분석 공부가 난생 처음인 입문자도 무리 없이 책을 끝까지 마칠 수 있습니다. 현장감 넘치는 스토리를 통해 데이터를 다루는 방법을 알려 주어 몰입감 있는 학습을 할 수 있도록 구성했습니다. 저자가 질문 하나하나에 직접 답변을 달아 주는 것은 물론, 최신 기술과 정보도 얻을 수 있습니다. 혼공 학습단과 함께하면 마지막까지 포기하지 않고 완주할 수 있을 것입니다. 꼭 기억해야 할 핵심 개념과 용어만 따로 정리한 [용어 노트]를 제공합니다. 새로운 용어를 추가하면서 자신만의 용어 노트를 완성해가는 과정도 재미가 될 것입니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "aff47dde",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BartConfig {\n",
       "  \"activation_dropout\": 0.0,\n",
       "  \"activation_function\": \"gelu\",\n",
       "  \"add_bias_logits\": false,\n",
       "  \"add_final_layer_norm\": false,\n",
       "  \"architectures\": [\n",
       "    \"BartForConditionalGeneration\"\n",
       "  ],\n",
       "  \"attention_dropout\": 0.0,\n",
       "  \"author\": \"EbanLee(rudwo6769@gmail.com)\",\n",
       "  \"bos_token_id\": 1,\n",
       "  \"classif_dropout\": 0.1,\n",
       "  \"classifier_dropout\": 0.1,\n",
       "  \"d_model\": 768,\n",
       "  \"decoder_attention_heads\": 16,\n",
       "  \"decoder_ffn_dim\": 3072,\n",
       "  \"decoder_layerdrop\": 0.0,\n",
       "  \"decoder_layers\": 6,\n",
       "  \"decoder_start_token_id\": 1,\n",
       "  \"do_blenderbot_90_layernorm\": false,\n",
       "  \"dropout\": 0.1,\n",
       "  \"encoder_attention_heads\": 16,\n",
       "  \"encoder_ffn_dim\": 3072,\n",
       "  \"encoder_layerdrop\": 0.0,\n",
       "  \"encoder_layers\": 6,\n",
       "  \"eos_token_id\": 1,\n",
       "  \"extra_pos_embeddings\": 2,\n",
       "  \"force_bos_token_to_be_generated\": false,\n",
       "  \"forced_eos_token_id\": 1,\n",
       "  \"gradient_checkpointing\": false,\n",
       "  \"id2label\": {\n",
       "    \"0\": \"NEGATIVE\",\n",
       "    \"1\": \"POSITIVE\"\n",
       "  },\n",
       "  \"init_std\": 0.02,\n",
       "  \"is_encoder_decoder\": true,\n",
       "  \"kobart_version\": 2.0,\n",
       "  \"label2id\": {\n",
       "    \"NEGATIVE\": 0,\n",
       "    \"POSITIVE\": 1\n",
       "  },\n",
       "  \"max_position_embeddings\": 1026,\n",
       "  \"model_type\": \"bart\",\n",
       "  \"normalize_before\": false,\n",
       "  \"normalize_embedding\": true,\n",
       "  \"num_hidden_layers\": 6,\n",
       "  \"pad_token_id\": 3,\n",
       "  \"scale_embedding\": false,\n",
       "  \"static_position_embeddings\": false,\n",
       "  \"task_specific_params\": {\n",
       "    \"summarization\": {\n",
       "      \"length_penalty\": 1.0,\n",
       "      \"max_length\": 300,\n",
       "      \"min_length\": 12,\n",
       "      \"no_repeat_ngram_size\": 15,\n",
       "      \"num_beams\": 6,\n",
       "      \"repetition_penalty\": 1.5\n",
       "    }\n",
       "  },\n",
       "  \"tokenizer_class\": \"PreTrainedTokenizerFast\",\n",
       "  \"torch_dtype\": \"float32\",\n",
       "  \"transformers_version\": \"4.53.1\",\n",
       "  \"use_cache\": true,\n",
       "  \"vocab_size\": 30000\n",
       "}"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kobart.model.config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e58d11ea",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
