선형 회귀
1. k-최근접 이웃의 한계
2. 선형 회귀

3. 다항 회귀
- 곡선의 직선 방정식을 구한다.
- 다차원 방정식
  y ax^2 + bx + c

==========================

특성 공학과 규제
키워드 정리
1. 다중 회귀
여러 개의 특성을 사용하는 회귀 모델입니다.
특성이 많으면 선형 모델은 강력한 성능을 발휘합니다.

2. 특성 공학
 - 특성의 갯수를 조합과 거듭제곱을 통해서 늘려주는 기법
 - PolynomialFeatures
 
3. 릿지
규제가 있는 선형 회귀 모델 중 하나이며 선형 모델의 계수를 작게 만들어 과대적합을 완화시킵니다.
릿지는 비교적 효과가 좋아 널리 사용하는 규제 방법입니다.

4. 라쏘
또 다른 규제가 있는 선형 회귀 모델입니다.
릿지와 달리 계수 값을 아예 0으로 만들 수도 있습니다.

5. 하이퍼파라미터 ********
머신러닝 알고리즘이 학습하지 않는 파라미터, 이런 파라미터는 사람이 사전에 지정해야 합니다.
릿지와 라쏘의 규제 강도 alpha 파라미터입니다.

핵심 패키지와 함수
1. pandas
1) read_csv()

2. scikit-learn
1) PolynomialFeatures
2) Ridge
3) Lasso

다중 회귀
1. 데이터 준비
2. 사이킷런의 변환기
3. 다중 회귀 모델 훈련하기

규제(정칙화)  *******
- 모델의 일반적인 경향성으로 개선
- 과대적합을 완화
- 특성에 대한 정규화가 필수
- alpha값 : 규제 강도
    - 값이 작을수록 규제 강도가 낮고
        - 너무 낮으면 과대적합(overfitting) 가능성이 커지고

    - 값이 클수록 규제 강도가 커진다
        - 너무 클수록 과소적합(underfitting) 가능성이 커진다

1. 릿지(Ridge)
    - L2 규제
    - 계수의 제곱으로 규제

2. 라쏘(Lasso)
    - L1 규제
    - 계수의 절대값으로 규제
    - 절편에 초점
    - 사용되지 않는 특성의 계수는 0으로 만들어 버린다.


규제를 가하는 이유
모델의 일반화를 위해서...
======================================

1. scikit-learn
1) cross_validate()
    cv=스플리터
        스플리터 클래스
            - KFold : 회기 모델 일때 사용
            - StratifiedKFold : 분류 모델일때 사용
        - n_splits : k-fold의 k갯수 설정
        - shuffle : 검증 세트를 섞어줄지 여부
2) GridSearchCV
 : 교차 검증을 통한 하이퍼 파라미터 자동 검색

3) RandomizedSearchCV
