
마켓과 머신러닝
0. 키워드 정리
1) 특성 : 데이터를 표현하는 하나의 성질
    - feature
    - 독립변수

    참고)
        정답
        - label
        - 종속변수

1. k-최근접 이웃 알고리즘
    - 비율이 많은 샘플로 정답을 결정하는 알고리즘

2. 모델
1) 알고리즘이 구현된 객체
2) 종종 알고리즘 자체를 모델이라고 부른다. 

3. 정확도
1) 정확한 답을 몇 개 맞췄는지 백분률로 나타낸 값
2) 사이킷런에서는 0~1 사이 값으로 출력된다.
3) 정확도 = (정확히 맞힌 갯수) / (전체 데이터 갯수)

4. 이진분류
1) 머신러닝에서 여러 개의 종류(혹은 클래스(class)라고 부릅니다) 중 하나를 구별해 내는 문제를 분류(classification)라고 부릅니다.
2) 2개의 클래스 중 하나를 고르는 문제를 이진 분류(binary classification)라고 합니다.

5. matplotlib 라이브러리
6. scikit-learn 라이브러리
KNeighborsClassifier()
    k-최근접 이웃 분류 모델을 만드는 클래스
    n_neighbors: 매개변수로 이웃의 개수를 지정합니다. 기본값은 5
    매개변수
        p: 거리를 재는 방법을 지정 *********
            1 : 맨해튼 거리 사용
            2 : 유클리디안 거리 사용
        n_jobs
            사용할 CPU 코어를 지정
            -1로 설정하면 모든 CPU 코어를 사용
            이웃 간의 거리 계산 속도는 높일 수 있으나 fit() 메서드에는 영향이 없음
            기본값은 1


    예제 - 생선 분류 문제
    1. 도미 데이터 준비하기 
    2. 방어 데이터 준비하기
    3. 첫 번째 머신러닝 프로그램
    1) 2차원 리스트 만들기
        -> 학습 데이터
        -> [
            [특성1, 특성2,...], 
            [특성1, 특성2,...]
        ]

    2) 정답 데이터 준비하기

4. k-최근접 이웃 알고리즘
- 어떤 데이터에 대한 답을 구할 때 주위의 다른 데이터를 보고 다수를 차지하는 것을 정답으로 사용
- k-최근접 이웃 알고리즘을 위해 준비해야 할 일은 데이터를 모두 가지고 있는 것이 전부
- 새로운 데이터에 대해 예측할 때는 가장 가까운 직선거리에 어떤 데이터가 있는지를 살피기만 하면 된다.
- 단점
    - k-최근접 이웃 알고리즘의 이런 특징 때문에 데이터가 아주 많은 경우 사용하기 어렵습니다.
    - 데이터가 크기 때문에 메모리가 많이 필요하고 직선거리를 계산하는 데도 많은 시간이 필요



    from sklearn.model_selection import train_test_split   **********
    nums5 = nums.reshape(-1, 1) #전체 열을 전체 행의 갯수   *******


fruits = np.array(['사과', '오렌지', '바나나','망고', '멜론'])
fruits[[1,2,3]]
fruits[[False, True, False, True, False]] #불리언 인덱싱